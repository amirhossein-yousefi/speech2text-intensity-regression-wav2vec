model_name: openai/whisper-small
language: en
dataset: librispeech_asr
train_split: train.clean.100
eval_split: validation.clean
test_split: test.clean
text_column: text
output_dir: outputs/whisper_small_mtl
learning_rate: 1.5e-4
per_device_train_batch_size: 8
per_device_eval_batch_size: 8
gradient_accumulation_steps: 2
num_train_epochs: 3
lambda_intensity: 1.0
warmup_steps: 500
fp16: true
generation_max_new_tokens: 128
label_smoothing_factor: 0.0
